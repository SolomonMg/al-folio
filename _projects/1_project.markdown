---
layout: page
title: Projecting Confidence
description: How the Probabilistic Horse Race Demobilizes the Public
img: /assets/img/anes_turnout_closerace_mc_tall.png
---

Inspired by Donald Trump's shocking victory over Hillary Clinton in the 2016 general election, Sean Westwood, Yphtach Lelkes and I set out to interrogate the question of whether elecion forecasts---particularly probablistic forecasts---might have helped to create a false sense of confidence in a Clinton victory, and ultimately led many on the left to stay home on election day. 

Clinton herself was quoted in [New York Magazine](http://nymag.com/daily/intelligencer/2017/05/hillary-clinton-life-after-election.html?mid=nymag_press) after the election:

> I had people literally seeking absolution... ‘_I’m so sorry I didn’t vote. I didn’t think you needed me._’ I don’t know how we’ll ever calculate how many people thought it was in the bag, because the percentages kept being thrown at people — ‘_Oh, she has an 88 percent chance to win!_’

Our work shows that probablistic election forecasts make a race look less competitive. Participants in a national probability survey-experiment were substantially more certain that one candidate would win a hypothetical race after seeing a probablistic forecast than after seeing the equivalent vote share estimate and margin of error. This is a big effect---those are confidence intervals not standard errors, with p-values below $$10^{-11}$$. 

![normal](/assets/img/certaintyc.png)

**Why might the left be more affected?**
 
Consider the figure above---the _candidate who is ahead in the polls_ is more affected. In 2016, that was Hillary. 

But irrespective of 2016, when you look at who engages with this material in both social media and television media, it's outlets with a left-leaning audience. The websites that present their poll aggregation results in terms of probabilities have left-leaning (negative) social media audiences---only realclearpolitics.com, which doesn’t emphasize win-probabilities, has a conservative audience:

![half](/assets/img/bma_science_alignment.png)

These data come from the average self-reported ideology of people who share links to various sites hosting poll-aggregators on Facebook, data that come from [this paper](http://science.sciencemag.org/content/early/2015/05/06/science.aaa1160.full)’s [replication materials](http://dx.doi.org/10.7910/DVN/LDJ7MS). 

When you look at the balance of coverage of probabilistic forecasts on major television broadcasts, there is more coverage on MSNBC, which has a more liberal audience.

![half](/assets/img/msnbc_mentions.png)


**What about voting?**

Perhaps most critically, we show that probabilistic forecasts showing more of a blowout can lower voting. In Study 1, we find limited evidence of this based on self reports. In Study 2, we show that when participants are faced with incentives designed to simulate real world voting, they are less likely to vote when probabilistic forecasts show higher odds of one candidate winning. Yet they are not responsive to changes in vote share.

![normal](/assets/img/FT_18.01.03_prob_vote.png)

**Could this actually affect real world voting?**

Consider 2016---an unusually high number of Democrats thought the leading candidate would *win by quite a bit*:

![normal](/assets/img/anes_turnout_closerace_mc_tall.png)

And people who say the leading candidate will *win by quite a bit* in pre-election polling are about three percentage points less likely to say they voted after the election than people who say it’s a close race. That’s after controlling for election year, prior turnout, and party identification. 

![normal](/assets/img/closerace_vote_anes.png)

The data here are from the [American National Election Study (ANES)](https://electionstudies.org) and go back to 1952.



Past work indicates that *uncertainty* in perceived pivotality affects turnout. Some of the best evidence comes from work that analyzes the effects of releasing exit polling results before voting ends, which clearly removes uncertainty. Work examining the effects of East Coast television networks’ “early calls” for one candidate or another on West Coast turnout generally find small but substantively meaningful effects, despite the fact that these calls occur late on election day {% cite carpini1984scooping %}. Similar work exploiting voting reform as a natural experiment shows a full 12 percentage point decrease in turnout in the French overseas territories that voted after exit polls were released [@Morton201565]. These designs also isolate the effect of information about closeness from campaigns’ tendencies to invest more in campaigns in competitive districts.

Other aggregate level studies find similar patterns consistent with a relationship between uncertainty and turnout. First of all, a large literature has demonstrated robust correlations between tighter elections and higher turnout [see @geys2006explaining; @cancela2016explaining for reviews]. Furthermore, @nicholson1997prior provide evidence from statistical models that prior election returns also explain turnout above and beyond campaign spending, particularly when good polling data is unavailable. With ANES data we show that from 1952-2016, people who said that one candidate will “win by quite a bit” in pre-election polling were less likely to vote, even after conditioning on prior turnout, year, party, and actual electoral college and popular vote margin (see Table A2 and Figure A3).

Field experiments provide additional evidence of a causal effect of how confidence in perceptions of electoral closeness can affect turnout. This literature finds substantive effects on turnout when polling results showing a closer race are delivered via telephone [among those who were reached, @biggers2017experimental] but null results when relying on postcards to deliver closeness messages [for which it’s not possible to verify the treatment was actually read, @gerber2017one; @biggers2017experimental].[^7] Finally, one study conducted in the weeks leading up to the 2012 presidential election found higher rates of self-reported, post-election turnout when delivering ostensible polling results *less* consistent with the extant polling data showing a comfortable Obama lead [@Vannette:2014vk].


A lot of past [research](https://huber.research.yale.edu/materials/67_paper.pdf) [shows](http://www2.gsu.edu/~polsnn/priorbeliefs.pdf) that when people [think](https://www.jstor.org/stable/1953324?seq=1#page_scan_tab_contents) an election is [in the bag](https://repository.upenn.edu/cgi/viewcontent.cgi?referer=&httpsredir=1&article=1018&context=asc_papers), they tend to [vote in real-world elections](https://www.sciencedirect.com/science/article/pii/S0014292115000483) at [lower rates](https://www.jstor.org/stable/2748722?seq=1#page_scan_tab_contents). Our study provides evidence that probabilistic forecasts give people more confidence that one candidate will win and suggestive evidence that we should expect them to vote at lower rates after seeing probabilistic forecasts.

Consider what else was different in 2016---there was much more material covering probablistic forecasts: 


![](/assets/img/forecast_google_news.png) 
Number of articles mentioning probabilistic forecasts indexed by Google News.

This research shows that election forecasts can make a race look less competitive and decrease voting. 
This is not merely academic because on balance liberals are more likely to see election forecasts.  


[**Projecting Confidence: How the Probabilistic Horse Race Confuses and Demobilizes the Public**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3117054).

With Sean Westwood and Yphtach Lelkes

- Media coverage: [Washington Post](https://www.washingtonpost.com/news/politics/wp/2018/02/06/clintons-achilles-heel-in-2016-may-have-been-overconfidence/?utm_term=.619133ce9312), [FiveThirthyEight’s Politics Podcast](https://fivethirtyeight.com/features/politics-podcast-whats-so-wrong-with-nancy-pelosi/), [New York Magazine](http://nymag.com/intelligencer/2018/02/americans-dont-understand-election-probabilities.html?gtm=bottom&gtm=bottom), [Political Wire](https://politicalwire.com/2018/02/06/election-forecasts-lower-voter-turnout/).

Abstract: Horse race coverage in American elections has shifted focus from late-breaking poll numbers to sophisticated meta analytic forecasts that often emphasize candidates' probability of victory. We place this "probabilistic horeserace" in the context of Riker and Ordeshook (1968), and hypothesize that it will lower uncertainty about an election's outcome (perceived potential pivotality), which lowers turnout under the model. After demonstrating the prominence of probabilistic forecasts in election coverage, we use experiments to show that the public has difficulty reasoning about the probability of a candidate’s victory. Critically, when one candidate is ahead, win-probabilities convey substantially more confidence that she will win compared to vote share estimates. Even more importantly, we show that these impressions of probabilistic forecasts cause people not to vote in a behavioral game that simulates elections. In the context of the existing literature, the magnitude of these findings suggests that probabilistic horse race coverage can confuse and demobilize the public.


{% bibliography --cited %}


